# Introduction {#intro}

```{r,include=FALSE}
knitr::opts_chunk$set(warning = FALSE,error = FALSE,message = FALSE)
```


## Topics of the week

During this week, we will cover a lot of *basic* and nonetheless indispensable tools for a data scientist. We will cover mainly the "boring side" of data science (aka data analysis :P ). As a matter of fact, if machine learning is more and more automatized, everything that is related to data **exploration**, **wrangling**, **cleaning**, **understanding** and **analysis** is hardly doable by "AI".

What's on our agenda :

- Introduction to R
- Data manipulation
- Introduction to statistics
- Data exploration 
- Explainable machine learning (eg regression)
- Data visualization
- Data cleaning
- Dimension reduction

**Important notes** : 

+ Of course, it's  not a linear path and the data science workflow is not a simple execution of those steps in a pre-determined order. It's all connected and you'll have to move back and forth between all of them to achieve your goal.  And this goal, what is it already ?
+ In data science is the word "science". And what is science ? Huge topic... But a few keywords that you should always have in mind when starting a project
    + Reproducibility
    + Hypothesis testing
    + Incremental
    + Iterative
    + Monitored

## The data science workflow

A very synthetic schematic of the data science workflow

![](img/data-science-explore.png)
This process is a part of a large scheme :

![](img/CRISP-DM_Process_Diagram.png)

## About the interactions with other colleagues

The previous iteration loop has to be done taking the business perspective / constraint into account !
More generally, the role of the data scientist is pretty central in use cases development. You will collaborate with other data/IT and business professionals :

- Data engineers
- Data architects
- Software engineers (DevOps)
- Machine learning engineers
- Data analysts
- Data strategists

- Program managers / product owners
- Business teams


And one challenge is to have all those different profiles working for one common goal and *communicate* together. My experience is that the data scientist can really put some oil in the machinery, aand one of her/his duty is to bridge the gap between business and IT worlds.


## Resources

You will find a lot of resources online. Here is a selection, mostly related to R. However, our goal for this session is to have you understand how all the methods we will cover are related to each other and when you should consider using them

- [R for data science](https://r4ds.had.co.nz/)
- [Statistics and econometrics](https://www.econometrics-with-r.org/)
- [Statistics and exploration with R](https://moderndive.com/)
- [From data to viz](https://www.data-to-viz.com/) (featuring python :D )
- [Data visualization]( https://socviz.co/)
- [More resource online books using R (text mining, machine learning...)](https://bookdown.org/home/)

## Data of the week

In this course, we will handle with my *own* personal data (I give my consent ! ;) )
Those are my sports activity data, which I got from garmin (thanks to the GDPR). If you want to get your own data from [this page](https://www.garmin.com/en-US/account/datamanagement/exportdata/).
Being a triathlete, there are several sports involved and a lot of activities. The goal will be to import, clean, analyze the data with statistics and eventually build some first models (**explainable AI**).

The export results in a lot of JSON files and we will focus on the summary data. It's real world data and you'll see it's complicated, dirty and requires a lot of preparation/manipulation !

```{r}
require(tidyverse)
dat <- read.csv("Data/Sports/Activities_2022.csv",header = T)
glimpse(dat)
```


## Your mission 

The data we will use as an example is quite messy, but it is a rather traditional tye of data that we will handle. However, you will face diverse type of data : time series, graphs, geospatial, panel,... That will require different analytical tools but also different ways to handle those objects. To provide you with a taste of those challenges ahead, your mission will be the following :

- Select the most important metrics of the activities (distance, duration, speed, power, elevation, heart rate....) and create monthly time series out of it (you will have to aggregate it ; please choose wisely how to aggregate : simple average can be inaccurate for ratios). Pick 4 of them.
- Learn by yourself the basics of time series and please describe for the chosen time series :
    + Draw the autocorrelation function
    + Is there a trend ?
    + Is there a seasonal pattern ?
    + Are those series stationary ? With which level of confidence can you assert so ? Please use 2 different tests.
- Prediction is the most common ML task for time series. Try the `prophet` and `auto.arima` algorithms to predict each time series 12 months ahead. What can you conclude ?
