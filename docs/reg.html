<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Linear and logistic regression | Data exploration and statistics with R and the tidyverse</title>
  <meta name="description" content="Welcome to the wonderful world of data science and R !" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Linear and logistic regression | Data exploration and statistics with R and the tidyverse" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Welcome to the wonderful world of data science and R !" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Linear and logistic regression | Data exploration and statistics with R and the tidyverse" />
  
  <meta name="twitter:description" content="Welcome to the wonderful world of data science and R !" />
  

<meta name="author" content="Vivien Roussez (GoStudent)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multivar.html"/>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data exploration and statistics with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Foreword</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#topics-of-the-week"><i class="fa fa-check"></i><b>2.1</b> Topics of the week</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#the-data-science-workflow"><i class="fa fa-check"></i><b>2.2</b> The data science workflow</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#about-the-interactions-with-other-colleagues"><i class="fa fa-check"></i><b>2.3</b> About the interactions with other colleagues</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#resources"><i class="fa fa-check"></i><b>2.4</b> Resources</a></li>
<li class="chapter" data-level="2.5" data-path="intro.html"><a href="intro.html#data-of-the-week"><i class="fa fa-check"></i><b>2.5</b> Data of the week</a></li>
<li class="chapter" data-level="2.6" data-path="intro.html"><a href="intro.html#your-mission"><i class="fa fa-check"></i><b>2.6</b> Your mission</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="intro_r.html"><a href="intro_r.html"><i class="fa fa-check"></i><b>3</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="intro_r.html"><a href="intro_r.html#what-is-r"><i class="fa fa-check"></i><b>3.1</b> What is R</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="intro_r.html"><a href="intro_r.html#description"><i class="fa fa-check"></i><b>3.1.1</b> Description</a></li>
<li class="chapter" data-level="3.1.2" data-path="intro_r.html"><a href="intro_r.html#objective-comparison-with-pyhton"><i class="fa fa-check"></i><b>3.1.2</b> (Objective) comparison with Pyhton</a></li>
<li class="chapter" data-level="3.1.3" data-path="intro_r.html"><a href="intro_r.html#what-can-i-do-with-r"><i class="fa fa-check"></i><b>3.1.3</b> What can I do with R</a></li>
<li class="chapter" data-level="3.1.4" data-path="intro_r.html"><a href="intro_r.html#quick-presentation-of-the-ecosystem"><i class="fa fa-check"></i><b>3.1.4</b> Quick presentation of the ecosystem</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="intro_r.html"><a href="intro_r.html#basic-commands-to-know"><i class="fa fa-check"></i><b>3.2</b> Basic commands to know</a></li>
<li class="chapter" data-level="3.3" data-path="intro_r.html"><a href="intro_r.html#data-structures-in-r"><i class="fa fa-check"></i><b>3.3</b> Data structures in R</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="intro_r.html"><a href="intro_r.html#basic-data-structures"><i class="fa fa-check"></i><b>3.3.1</b> Basic data structures</a></li>
<li class="chapter" data-level="3.3.2" data-path="intro_r.html"><a href="intro_r.html#explore-a-new-data-structure-or-object"><i class="fa fa-check"></i><b>3.3.2</b> Explore a new data structure (or object)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="manip.html"><a href="manip.html"><i class="fa fa-check"></i><b>4</b> Data manipulation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="manip.html"><a href="manip.html#import"><i class="fa fa-check"></i><b>4.1</b> Import</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="manip.html"><a href="manip.html#text-files"><i class="fa fa-check"></i><b>4.1.1</b> Text files</a></li>
<li class="chapter" data-level="4.1.2" data-path="manip.html"><a href="manip.html#excel-files"><i class="fa fa-check"></i><b>4.1.2</b> Excel files</a></li>
<li class="chapter" data-level="4.1.3" data-path="manip.html"><a href="manip.html#more-formats"><i class="fa fa-check"></i><b>4.1.3</b> More formats</a></li>
<li class="chapter" data-level="4.1.4" data-path="manip.html"><a href="manip.html#read-from-databases-big-data"><i class="fa fa-check"></i><b>4.1.4</b> Read from databases / big data</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="manip.html"><a href="manip.html#the-grammar-of-data-manipulation"><i class="fa fa-check"></i><b>4.2</b> The grammar of data manipulation</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="manip.html"><a href="manip.html#the-pipe"><i class="fa fa-check"></i><b>4.2.1</b> The pipe</a></li>
<li class="chapter" data-level="4.2.2" data-path="manip.html"><a href="manip.html#the-verbs-of-manipulation"><i class="fa fa-check"></i><b>4.2.2</b> The verbs of manipulation</a></li>
<li class="chapter" data-level="4.2.3" data-path="manip.html"><a href="manip.html#filter-conditions"><i class="fa fa-check"></i><b>4.2.3</b> Filter : conditions</a></li>
<li class="chapter" data-level="4.2.4" data-path="manip.html"><a href="manip.html#mutate"><i class="fa fa-check"></i><b>4.2.4</b> Mutate</a></li>
<li class="chapter" data-level="4.2.5" data-path="manip.html"><a href="manip.html#summarize"><i class="fa fa-check"></i><b>4.2.5</b> Summarize</a></li>
<li class="chapter" data-level="4.2.6" data-path="manip.html"><a href="manip.html#join-with-other-tables"><i class="fa fa-check"></i><b>4.2.6</b> Join with other tables</a></li>
<li class="chapter" data-level="4.2.7" data-path="manip.html"><a href="manip.html#manipulate-several-data-in-the-same-time"><i class="fa fa-check"></i><b>4.2.7</b> Manipulate several data in the same time</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="manip.html"><a href="manip.html#lets-import-and-wrangle-some-data"><i class="fa fa-check"></i><b>4.3</b> Let’s import and wrangle some data !</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="manip.html"><a href="manip.html#the-data"><i class="fa fa-check"></i><b>4.3.1</b> The data</a></li>
<li class="chapter" data-level="4.3.2" data-path="manip.html"><a href="manip.html#one-tool-you-will-need-lapply"><i class="fa fa-check"></i><b>4.3.2</b> One tool you will need : <code>lapply()</code></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="manip.html"><a href="manip.html#tidy-your-data"><i class="fa fa-check"></i><b>4.4</b> Tidy your data</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="stats.html"><a href="stats.html"><i class="fa fa-check"></i><b>5</b> Statistics</a>
<ul>
<li class="chapter" data-level="5.1" data-path="stats.html"><a href="stats.html#definitions"><i class="fa fa-check"></i><b>5.1</b> Definitions</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="stats.html"><a href="stats.html#terminology"><i class="fa fa-check"></i><b>5.1.1</b> Terminology</a></li>
<li class="chapter" data-level="5.1.2" data-path="stats.html"><a href="stats.html#types-of-variables"><i class="fa fa-check"></i><b>5.1.2</b> Types of variables</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="stats.html"><a href="stats.html#univariate-statistics"><i class="fa fa-check"></i><b>5.2</b> Univariate statistics</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="stats.html"><a href="stats.html#numerical-variables"><i class="fa fa-check"></i><b>5.2.1</b> Numerical variables</a></li>
<li class="chapter" data-level="5.2.2" data-path="stats.html"><a href="stats.html#categorical-variables"><i class="fa fa-check"></i><b>5.2.2</b> Categorical variables</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="stats.html"><a href="stats.html#bivariate-statistics"><i class="fa fa-check"></i><b>5.3</b> Bivariate statistics</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="stats.html"><a href="stats.html#continuous-variables"><i class="fa fa-check"></i><b>5.3.1</b> 2 continuous variables</a></li>
<li class="chapter" data-level="5.3.2" data-path="stats.html"><a href="stats.html#categorical-variables-1"><i class="fa fa-check"></i><b>5.3.2</b> 2 categorical variables</a></li>
<li class="chapter" data-level="5.3.3" data-path="stats.html"><a href="stats.html#continuous-1-categorical-variable"><i class="fa fa-check"></i><b>5.3.3</b> 1 continuous, 1 categorical variable</a></li>
<li class="chapter" data-level="5.3.4" data-path="stats.html"><a href="stats.html#exercises-1"><i class="fa fa-check"></i><b>5.3.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="stats.html"><a href="stats.html#stat_inf"><i class="fa fa-check"></i><b>5.4</b> Statistical inference</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="stats.html"><a href="stats.html#the-statistical-model"><i class="fa fa-check"></i><b>5.4.1</b> The statistical model</a></li>
<li class="chapter" data-level="5.4.2" data-path="stats.html"><a href="stats.html#two-fundamental-theorems"><i class="fa fa-check"></i><b>5.4.2</b> Two fundamental theorems</a></li>
<li class="chapter" data-level="5.4.3" data-path="stats.html"><a href="stats.html#statistical-tests"><i class="fa fa-check"></i><b>5.4.3</b> Statistical tests</a></li>
<li class="chapter" data-level="5.4.4" data-path="stats.html"><a href="stats.html#other-estimators-maximum-of-likelihood"><i class="fa fa-check"></i><b>5.4.4</b> Other estimators : maximum of likelihood</a></li>
<li class="chapter" data-level="5.4.5" data-path="stats.html"><a href="stats.html#exercises-interprete-a-test-you-dont-know"><i class="fa fa-check"></i><b>5.4.5</b> Exercises : interprete a test you don’t know</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multivar.html"><a href="multivar.html"><i class="fa fa-check"></i><b>6</b> Multivariate analysis and dimension reduction</a>
<ul>
<li class="chapter" data-level="6.1" data-path="multivar.html"><a href="multivar.html#multivariate-analysis"><i class="fa fa-check"></i><b>6.1</b> Multivariate analysis</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="multivar.html"><a href="multivar.html#advanced-visualization"><i class="fa fa-check"></i><b>6.1.1</b> Advanced visualization</a></li>
<li class="chapter" data-level="6.1.2" data-path="multivar.html"><a href="multivar.html#easily-explore-an-entire-dataset"><i class="fa fa-check"></i><b>6.1.2</b> Easily explore an entire dataset</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="multivar.html"><a href="multivar.html#multivariate-analysis-and-dimension-reduction"><i class="fa fa-check"></i><b>6.2</b> Multivariate analysis and dimension reduction</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="multivar.html"><a href="multivar.html#imputation"><i class="fa fa-check"></i><b>6.2.1</b> Imputation</a></li>
<li class="chapter" data-level="6.2.2" data-path="multivar.html"><a href="multivar.html#normalization"><i class="fa fa-check"></i><b>6.2.2</b> Normalization</a></li>
<li class="chapter" data-level="6.2.3" data-path="multivar.html"><a href="multivar.html#pca"><i class="fa fa-check"></i><b>6.2.3</b> PCA</a></li>
<li class="chapter" data-level="6.2.4" data-path="multivar.html"><a href="multivar.html#exercises-2"><i class="fa fa-check"></i><b>6.2.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="multivar.html"><a href="multivar.html#dimension-reduction"><i class="fa fa-check"></i><b>6.3</b> Dimension reduction</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="multivar.html"><a href="multivar.html#use-the-results-of-the-pca"><i class="fa fa-check"></i><b>6.3.1</b> Use the results of the PCA</a></li>
<li class="chapter" data-level="6.3.2" data-path="multivar.html"><a href="multivar.html#other-inertia-based-methods"><i class="fa fa-check"></i><b>6.3.2</b> Other inertia-based methods</a></li>
<li class="chapter" data-level="6.3.3" data-path="multivar.html"><a href="multivar.html#t-sne"><i class="fa fa-check"></i><b>6.3.3</b> t-SNE</a></li>
<li class="chapter" data-level="6.3.4" data-path="multivar.html"><a href="multivar.html#a-word-about-clustering"><i class="fa fa-check"></i><b>6.3.4</b> A word about clustering</a></li>
<li class="chapter" data-level="6.3.5" data-path="multivar.html"><a href="multivar.html#exercise-1"><i class="fa fa-check"></i><b>6.3.5</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="multivar.html"><a href="multivar.html#visualization-bonus-dashboards-and-reports"><i class="fa fa-check"></i><b>6.4</b> Visualization bonus : dashboards and reports</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="multivar.html"><a href="multivar.html#shiny-and-rmarkdown"><i class="fa fa-check"></i><b>6.4.1</b> Shiny and rmarkdown</a></li>
<li class="chapter" data-level="6.4.2" data-path="multivar.html"><a href="multivar.html#web-based-graphics-with-plotly"><i class="fa fa-check"></i><b>6.4.2</b> Web-based graphics with <code>plotly</code></a></li>
<li class="chapter" data-level="6.4.3" data-path="multivar.html"><a href="multivar.html#other-packages-widgets"><i class="fa fa-check"></i><b>6.4.3</b> Other packages &amp; widgets</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="reg.html"><a href="reg.html"><i class="fa fa-check"></i><b>7</b> Linear and logistic regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="reg.html"><a href="reg.html#linear-regression"><i class="fa fa-check"></i><b>7.1</b> Linear regression</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="reg.html"><a href="reg.html#general-presentation"><i class="fa fa-check"></i><b>7.1.1</b> General presentation</a></li>
<li class="chapter" data-level="7.1.2" data-path="reg.html"><a href="reg.html#implementation-and-diagnostics"><i class="fa fa-check"></i><b>7.1.2</b> Implementation and diagnostics</a></li>
<li class="chapter" data-level="7.1.3" data-path="reg.html"><a href="reg.html#coefficients-interpretation-and-inference"><i class="fa fa-check"></i><b>7.1.3</b> Coefficients interpretation and inference</a></li>
<li class="chapter" data-level="7.1.4" data-path="reg.html"><a href="reg.html#the-frischwaugh-theorem-and-the-omitted-variable-bias"><i class="fa fa-check"></i><b>7.1.4</b> The Frisch–Waugh Theorem and the omitted variable bias</a></li>
<li class="chapter" data-level="7.1.5" data-path="reg.html"><a href="reg.html#feature-engineering-and-functional-specification"><i class="fa fa-check"></i><b>7.1.5</b> Feature engineering and functional specification</a></li>
<li class="chapter" data-level="7.1.6" data-path="reg.html"><a href="reg.html#variable-selection"><i class="fa fa-check"></i><b>7.1.6</b> Variable selection</a></li>
<li class="chapter" data-level="7.1.7" data-path="reg.html"><a href="reg.html#exercises-3"><i class="fa fa-check"></i><b>7.1.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="reg.html"><a href="reg.html#logitic-regression"><i class="fa fa-check"></i><b>7.2</b> Logitic regression</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="reg.html"><a href="reg.html#mathematical-formulation"><i class="fa fa-check"></i><b>7.2.1</b> Mathematical formulation</a></li>
<li class="chapter" data-level="7.2.2" data-path="reg.html"><a href="reg.html#implementation-in-r-and-interpretation"><i class="fa fa-check"></i><b>7.2.2</b> Implementation in R and interpretation</a></li>
<li class="chapter" data-level="7.2.3" data-path="reg.html"><a href="reg.html#goodness-of-fit"><i class="fa fa-check"></i><b>7.2.3</b> Goodness of fit</a></li>
<li class="chapter" data-level="7.2.4" data-path="reg.html"><a href="reg.html#exercises-4"><i class="fa fa-check"></i><b>7.2.4</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data exploration and statistics with R and the tidyverse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="reg" class="section level1" number="7">
<h1><span class="header-section-number">Chapter 7</span> Linear and logistic regression</h1>
<p>Regression is the first machine learning algorithm. It allows you to model a <em>target variable</em> <span class="math inline">\(y\)</span> depending on a set of <em>explanatory variables</em> or <em>features</em> <span class="math inline">\(X\)</span> such that <span class="math inline">\(y=f(X) + \epsilon\)</span> where <span class="math inline">\(f\)</span> is a linear function (for linear regression).</p>
<div id="linear-regression" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Linear regression</h2>
<p>We will jump directly to the <em>multiple regression model</em>, which is the generalization of the simple linear model, which you can check <a href="https://www.econometrics-with-r.org/4-lrwor.html">here</a></p>
<div id="general-presentation" class="section level3" number="7.1.1">
<h3><span class="header-section-number">7.1.1</span> General presentation</h3>
<p>The basic equation of the linear regression is
<span class="math display">\[ y_i = x_i \cdot b + \epsilon_i \Leftrightarrow y_i = \sum_{j=1}^p x_{ij} b_j + \epsilon_i\]</span></p>
<p>Where :</p>
<ul>
<li><span class="math inline">\(x_i\)</span> is a row-vector of size p (number of explanatory variables), containng the values of each feature of observation i. It is the row i of the matrix <span class="math inline">\(X = (x_{ij})\)</span></li>
<li>b is a column-vector of coefficients, one per explanatory variable</li>
<li><span class="math inline">\(\epsilon_i\)</span> is the error term for observation i</li>
</ul>
<p>This regression is said to be linear because it is <em>linear in the parameters</em>, you can however transform the original variables at will with non-linear functions (see feature engineering).</p>
<p>The biggest assumptions of this model are :</p>
<ul>
<li>Observations are iid</li>
<li>There is no perfect multi-collinearity among features</li>
<li><span class="math inline">\(\epsilon_i\)</span> has a zero conditional mean <span class="math inline">\(\mathbb{E}(\epsilon | X)=0\)</span></li>
</ul>
<p>This last condition helps us to derive an estimator for b (which can be derived in several ways) which is called the OLS estimator (Ordinary Least Squares), which is the solution of the optimization program :</p>
<p><span class="math display">\[\hat{b}=argmin_b \sum_{i=1}^n \epsilon_i^2 = argmin_b \sum_{i=1}^n (y_i-x_i \cdot b)^2\]</span></p>
<p>The solution is <span class="math inline">\(\hat{b} = (X&#39;X)^{-1}X&#39;y\)</span> where <span class="math inline">\(X&#39;=t(X)\)</span>. <span class="math inline">\((X&#39;X)^{-1}X\)</span> is the projection matrix over the hyperplane defined by the features.</p>
<p><img src="img/ols-regression-geometry.png" /></p>
</div>
<div id="implementation-and-diagnostics" class="section level3" number="7.1.2">
<h3><span class="header-section-number">7.1.2</span> Implementation and diagnostics</h3>
<p>To implement a linear regression with R, we use the <code>lm</code> function :</p>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="reg.html#cb247-1" aria-hidden="true" tabindex="-1"></a>reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(avgSpeed<span class="sc">~</span>avgPower <span class="sc">+</span> avgBikeCadence <span class="sc">+</span> distance <span class="sc">+</span> avgHr <span class="sc">+</span> max20MinPower, <span class="at">data=</span>dat_bike)</span>
<span id="cb247-2"><a href="reg.html#cb247-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(reg)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = avgSpeed ~ avgPower + avgBikeCadence + distance + 
##     avgHr + max20MinPower, data = dat_bike)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -39.858  -4.934  -0.770   4.946  23.774 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    108.95343    4.94740  22.022   &lt;2e-16 ***
## avgPower         0.29912    0.01782  16.789   &lt;2e-16 ***
## avgBikeCadence  -1.41070    0.04489 -31.428   &lt;2e-16 ***
## distance         0.11346    0.00917  12.373   &lt;2e-16 ***
## avgHr           -0.01114    0.02210  -0.504    0.614    
## max20MinPower   -0.12324    0.01369  -9.005   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.425 on 920 degrees of freedom
##   (1909 observations deleted due to missingness)
## Multiple R-squared:  0.7813, Adjusted R-squared:  0.7802 
## F-statistic: 657.5 on 5 and 920 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The goodness of fit is measured through 2 main statistics :</p>
<ul>
<li>Adjusted R-squared, <span class="math inline">\(1- \dfrac{n-1}{n-k-1} \dfrac{SSR}{TSS} \in [0,1]\)</span>, which takes the number of regressors into account. The closer to 1, the better the fit</li>
<li>RMSE (root mean squared error), or residual standard error which has to be compared to the average value of <span class="math inline">\(y\)</span>. the smaller the value, the better the fit.</li>
</ul>
</div>
<div id="coefficients-interpretation-and-inference" class="section level3" number="7.1.3">
<h3><span class="header-section-number">7.1.3</span> Coefficients interpretation and inference</h3>
<p>Back to original equation, we can understand how much each feature influences in average the output.</p>
<p><span class="math display">\[ \dfrac{\partial y}{\partial x_1} = b_1\]</span>
Meaning that the increase of <span class="math inline">\(x_1\)</span> by one unit causes the output to increase in average by <span class="math inline">\(b_1\)</span> (which can of course be negative). In our example, one additional watt will result in an increase of the average speed by 0.25 km/h</p>
<p>The fundamental hypothesis being fulfilled and the sample being large enough, the distribution of the OLS estimate <span class="math inline">\((b_1,...,b_p)\)</span> are jointly normally distributed, meaning that each <span class="math inline">\(\hat{b_j} \hookrightarrow \mathcal{N}(b_j,\sigma_{b_j}^2)\)</span>
We can therefore perform statistical tests following the previous methodology (see @ref(stat_inf).</p>
<p>The most common test is the Student test which tests the null hypothesis <span class="math inline">\(b_i=0\)</span>. This allows to check whether a regressor has a significant effect on the target variable or not.</p>
<p>But you have to check your residuals !</p>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="reg.html#cb249-1" aria-hidden="true" tabindex="-1"></a><span class="fu">residuals</span>(reg) <span class="sc">%&gt;%</span> </span>
<span id="cb249-2"><a href="reg.html#cb249-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.frame</span>(<span class="at">res=</span>.) <span class="sc">%&gt;%</span> </span>
<span id="cb249-3"><a href="reg.html#cb249-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(res)) <span class="sc">+</span> <span class="fu">geom_density</span>() <span class="sc">+</span> <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="DataExploration_files/figure-html/unnamed-chunk-98-1.png" width="672" />
Those are pretty long tailed, which might reflect some outliers or a wrong functional specification !</p>
</div>
<div id="the-frischwaugh-theorem-and-the-omitted-variable-bias" class="section level3" number="7.1.4">
<h3><span class="header-section-number">7.1.4</span> The Frisch–Waugh Theorem and the omitted variable bias</h3>
<p>The <a href="https://en.wikipedia.org/wiki/Frisch%E2%80%93Waugh%E2%80%93Lovell_theorem">Frisch-Waugh theorem</a> tells us that adding a variable as regressor ensures that our estimates controls for the effect of this variable. In other words, you can interpret the coefficients’ values <em>ceteris paribus</em> (other things equal).</p>
<p>This also means that if you omit a variable, the coefficient of the other variables are likely to be biased, because you did not take an important variable into account. Back to our example, we can add the elevationGain variable and check what happens :</p>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="reg.html#cb250-1" aria-hidden="true" tabindex="-1"></a>reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(avgSpeed<span class="sc">~</span>avgPower <span class="sc">+</span> avgBikeCadence <span class="sc">+</span> distance <span class="sc">+</span> avgHr <span class="sc">+</span> max20MinPower <span class="sc">+</span> elevationGain, <span class="at">data=</span>dat_bike)</span>
<span id="cb250-2"><a href="reg.html#cb250-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(reg)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = avgSpeed ~ avgPower + avgBikeCadence + distance + 
##     avgHr + max20MinPower + elevationGain, data = dat_bike)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -29.0440  -4.1401  -0.2226   3.6978  19.4709 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     1.145e+02  4.572e+00  25.032  &lt; 2e-16 ***
## avgPower        1.762e-01  1.683e-02  10.468  &lt; 2e-16 ***
## avgBikeCadence -1.396e+00  4.485e-02 -31.132  &lt; 2e-16 ***
## distance        2.041e-01  1.002e-02  20.364  &lt; 2e-16 ***
## avgHr           1.299e-02  1.916e-02   0.678  0.49799    
## max20MinPower  -3.758e-02  1.297e-02  -2.898  0.00386 ** 
## elevationGain  -1.358e-02  7.626e-04 -17.805  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.283 on 754 degrees of freedom
##   (2074 observations deleted due to missingness)
## Multiple R-squared:  0.7441, Adjusted R-squared:  0.742 
## F-statistic: 365.3 on 6 and 754 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>See how the coefficients changed. This is understandable because when climbing mountains :</p>
<ul>
<li>More power will not increase the speed, just maintain it (… or not)</li>
<li>The cadence is harder to maintain unless you have unlimited gears !</li>
<li>The surprising negative effect of the max20MinPower is no more</li>
</ul>
<p>Notice though that the RMSE and the adjusted <span class="math inline">\(R^2\)</span> degraded… See the variable selection to see how to mitigate that problem.</p>
</div>
<div id="feature-engineering-and-functional-specification" class="section level3" number="7.1.5">
<h3><span class="header-section-number">7.1.5</span> Feature engineering and functional specification</h3>
<p>The omitted variable bias makes it very important to include as much variables as possible if you want to be able to estimate the coefficient as accurately as possible. What you can do is add :</p>
<ul>
<li>Exponents to the regressors</li>
<li>Interactions between regressors</li>
</ul>
<p>Example with 2 variables <span class="math inline">\(y=b_1x_1 + b_2x_2 + b_3x_1^2 + b_4x_1x_2 + \epsilon\)</span></p>
<p>In this case : <span class="math inline">\(\dfrac{\partial y}{\partial x1} = b_1+2b_3x_1+b_4x_2\)</span></p>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb252-1"><a href="reg.html#cb252-1" aria-hidden="true" tabindex="-1"></a>reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(avgSpeed<span class="sc">~</span> avgPower <span class="sc">+</span> <span class="fu">I</span>(avgPower<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> avgBikeCadence <span class="sc">+</span> </span>
<span id="cb252-2"><a href="reg.html#cb252-2" aria-hidden="true" tabindex="-1"></a>             distance <span class="sc">+</span> <span class="fu">I</span>(avgPower<span class="sc">*</span>distance)<span class="sc">+</span>  avgHr <span class="sc">+</span> max20MinPower , <span class="at">data=</span>dat_bike)</span>
<span id="cb252-3"><a href="reg.html#cb252-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(reg)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = avgSpeed ~ avgPower + I(avgPower^2) + avgBikeCadence + 
##     distance + I(avgPower * distance) + avgHr + max20MinPower, 
##     data = dat_bike)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -39.079  -4.647  -0.741   4.600  23.527 
## 
## Coefficients:
##                          Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)            98.6948840 12.6015315   7.832 1.32e-14 ***
## avgPower                0.2597003  0.0974026   2.666  0.00781 ** 
## I(avgPower^2)           0.0002079  0.0001771   1.174  0.24056    
## avgBikeCadence         -1.3118683  0.0478793 -27.399  &lt; 2e-16 ***
## distance                0.5386573  0.0776404   6.938 7.51e-12 ***
## I(avgPower * distance) -0.0016752  0.0003052  -5.489 5.22e-08 ***
## avgHr                  -0.0232959  0.0218618  -1.066  0.28689    
## max20MinPower          -0.1228978  0.0137991  -8.906  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.309 on 918 degrees of freedom
##   (1909 observations deleted due to missingness)
## Multiple R-squared:  0.7886, Adjusted R-squared:  0.787 
## F-statistic: 489.2 on 7 and 918 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb254-1"><a href="reg.html#cb254-1" aria-hidden="true" tabindex="-1"></a>reg_full <span class="ot">&lt;-</span> <span class="fu">lm</span>(avgSpeed<span class="sc">~</span>(avgPower <span class="sc">+</span> avgBikeCadence <span class="sc">+</span> distance <span class="sc">+</span> avgHr <span class="sc">+</span> max20MinPower <span class="sc">+</span> elevationGain)<span class="sc">^</span><span class="dv">2</span>, <span class="at">data=</span>dat_bike)</span>
<span id="cb254-2"><a href="reg.html#cb254-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(reg_full)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = avgSpeed ~ (avgPower + avgBikeCadence + distance + 
##     avgHr + max20MinPower + elevationGain)^2, data = dat_bike)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -19.5744  -2.3189  -0.2251   2.0763  20.4421 
## 
## Coefficients:
##                                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                   1.961e+02  3.265e+01   6.005 3.00e-09 ***
## avgPower                      1.553e+00  2.211e-01   7.024 4.89e-12 ***
## avgBikeCadence               -2.072e+00  3.737e-01  -5.545 4.09e-08 ***
## distance                     -4.109e-01  1.872e-01  -2.196   0.0284 *  
## avgHr                        -1.244e-01  2.728e-01  -0.456   0.6485    
## max20MinPower                -1.518e+00  2.015e-01  -7.532 1.46e-13 ***
## elevationGain                -7.480e-02  1.452e-02  -5.152 3.32e-07 ***
## avgPower:avgBikeCadence      -1.382e-02  2.412e-03  -5.730 1.47e-08 ***
## avgPower:distance             8.225e-04  6.085e-04   1.352   0.1769    
## avgPower:avgHr               -7.919e-04  1.134e-03  -0.699   0.4850    
## avgPower:max20MinPower        3.357e-05  1.976e-04   0.170   0.8651    
## avgPower:elevationGain       -3.885e-04  4.514e-05  -8.606  &lt; 2e-16 ***
## avgBikeCadence:distance       1.380e-02  2.071e-03   6.663 5.25e-11 ***
## avgBikeCadence:avgHr         -9.734e-04  2.916e-03  -0.334   0.7386    
## avgBikeCadence:max20MinPower  1.408e-02  1.927e-03   7.305 7.21e-13 ***
## avgBikeCadence:elevationGain  6.942e-04  1.302e-04   5.330 1.30e-07 ***
## distance:avgHr               -1.022e-03  6.800e-04  -1.503   0.1332    
## distance:max20MinPower       -2.629e-03  4.449e-04  -5.910 5.22e-09 ***
## distance:elevationGain        2.655e-05  1.050e-05   2.529   0.0117 *  
## avgHr:max20MinPower           1.664e-03  1.051e-03   1.583   0.1140    
## avgHr:elevationGain           1.373e-04  7.622e-05   1.802   0.0720 .  
## max20MinPower:elevationGain   2.854e-04  2.685e-05  10.626  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.606 on 739 degrees of freedom
##   (2074 observations deleted due to missingness)
## Multiple R-squared:  0.8652, Adjusted R-squared:  0.8614 
## F-statistic: 225.9 on 21 and 739 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="variable-selection" class="section level3" number="7.1.6">
<h3><span class="header-section-number">7.1.6</span> Variable selection</h3>
<p>So far we focused on getting the best coefficient estimates to be able to interpret how features impact our target variable (“explainable AI”), but following the previous logic, adding the more feature the better ! However, when focusing on the best prediction, you are more interested in finding the most general model which will perform well <em>out of sample</em> adding more and more variables can lead, as a matter of fact, to an overfitted model, which will hardly generalize.</p>
<p>This is illustration of the bias-variance trade-off which you will see more in depth during the machine learning session.</p>
<p><img src="img/Overfitting.png" />
Regarding regression, avoiding overfitting can be done with variable selection : starting from an extensive model, the procedure will try every feature combination that leads to the best prediction. There are 3 ways of constructing the models :</p>
<ul>
<li>backward selection : remove the less useful feature at a time</li>
<li>forward selection : introduce the most useful feature at a time</li>
<li>stepwise selection : a mixture of the previous methods</li>
</ul>
<p>The quality of each model is determined by the <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion">AIC</a> or <a href="https://en.wikipedia.org/wiki/Bayesian_information_criterion">BIC</a> which are a function of the opposite of the log-likelihood (because OLS can also be estimated with MLE) and the number of parameters. The lower this number, the better the model.</p>
<p>We can implement this method easily</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="reg.html#cb256-1" aria-hidden="true" tabindex="-1"></a>selection <span class="ot">&lt;-</span> <span class="fu">step</span>(reg_full)</span></code></pre></div>
<pre><code>## Start:  AIC=2346.23
## avgSpeed ~ (avgPower + avgBikeCadence + distance + avgHr + max20MinPower + 
##     elevationGain)^2
## 
##                                Df Sum of Sq   RSS    AIC
## - avgPower:max20MinPower        1      0.61 15677 2344.3
## - avgBikeCadence:avgHr          1      2.36 15678 2344.3
## - avgPower:avgHr                1     10.35 15686 2344.7
## - avgPower:distance             1     38.75 15715 2346.1
## &lt;none&gt;                                      15676 2346.2
## - distance:avgHr                1     47.93 15724 2346.6
## - avgHr:max20MinPower           1     53.13 15729 2346.8
## - avgHr:elevationGain           1     68.85 15745 2347.6
## - distance:elevationGain        1    135.64 15812 2350.8
## - avgBikeCadence:elevationGain  1    602.68 16279 2372.9
## - avgPower:avgBikeCadence       1    696.37 16372 2377.3
## - distance:max20MinPower        1    740.94 16417 2379.4
## - avgBikeCadence:distance       1    941.73 16618 2388.6
## - avgBikeCadence:max20MinPower  1   1131.87 16808 2397.3
## - avgPower:elevationGain        1   1570.92 17247 2416.9
## - max20MinPower:elevationGain   1   2395.30 18072 2452.4
## 
## Step:  AIC=2344.26
## avgSpeed ~ avgPower + avgBikeCadence + distance + avgHr + max20MinPower + 
##     elevationGain + avgPower:avgBikeCadence + avgPower:distance + 
##     avgPower:avgHr + avgPower:elevationGain + avgBikeCadence:distance + 
##     avgBikeCadence:avgHr + avgBikeCadence:max20MinPower + avgBikeCadence:elevationGain + 
##     distance:avgHr + distance:max20MinPower + distance:elevationGain + 
##     avgHr:max20MinPower + avgHr:elevationGain + max20MinPower:elevationGain
## 
##                                Df Sum of Sq   RSS    AIC
## - avgBikeCadence:avgHr          1      2.45 15679 2342.4
## - avgPower:avgHr                1      9.74 15686 2342.7
## - avgPower:distance             1     38.31 15715 2344.1
## &lt;none&gt;                                      15677 2344.3
## - distance:avgHr                1     49.74 15726 2344.7
## - avgHr:max20MinPower           1     56.24 15733 2345.0
## - avgHr:elevationGain           1     68.51 15745 2345.6
## - distance:elevationGain        1    136.21 15813 2348.8
## - avgBikeCadence:elevationGain  1    603.23 16280 2371.0
## - avgPower:avgBikeCadence       1    698.23 16375 2375.4
## - distance:max20MinPower        1    764.90 16442 2378.5
## - avgBikeCadence:distance       1    947.00 16624 2386.9
## - avgBikeCadence:max20MinPower  1   1134.60 16811 2395.4
## - avgPower:elevationGain        1   1615.03 17292 2416.9
## - max20MinPower:elevationGain   1   2404.88 18082 2450.9
## 
## Step:  AIC=2342.37
## avgSpeed ~ avgPower + avgBikeCadence + distance + avgHr + max20MinPower + 
##     elevationGain + avgPower:avgBikeCadence + avgPower:distance + 
##     avgPower:avgHr + avgPower:elevationGain + avgBikeCadence:distance + 
##     avgBikeCadence:max20MinPower + avgBikeCadence:elevationGain + 
##     distance:avgHr + distance:max20MinPower + distance:elevationGain + 
##     avgHr:max20MinPower + avgHr:elevationGain + max20MinPower:elevationGain
## 
##                                Df Sum of Sq   RSS    AIC
## - avgPower:avgHr                1      9.62 15689 2340.8
## - avgPower:distance             1     37.59 15717 2342.2
## &lt;none&gt;                                      15679 2342.4
## - distance:avgHr                1     52.05 15731 2342.9
## - avgHr:max20MinPower           1     55.42 15735 2343.1
## - avgHr:elevationGain           1     76.51 15756 2344.1
## - distance:elevationGain        1    135.62 15815 2346.9
## - avgBikeCadence:elevationGain  1    610.23 16290 2369.4
## - avgPower:avgBikeCadence       1    755.98 16435 2376.2
## - distance:max20MinPower        1    763.12 16442 2376.5
## - avgBikeCadence:distance       1    961.69 16641 2385.7
## - avgBikeCadence:max20MinPower  1   1144.49 16824 2394.0
## - avgPower:elevationGain        1   1638.36 17318 2416.0
## - max20MinPower:elevationGain   1   2403.13 18082 2448.9
## 
## Step:  AIC=2340.84
## avgSpeed ~ avgPower + avgBikeCadence + distance + avgHr + max20MinPower + 
##     elevationGain + avgPower:avgBikeCadence + avgPower:distance + 
##     avgPower:elevationGain + avgBikeCadence:distance + avgBikeCadence:max20MinPower + 
##     avgBikeCadence:elevationGain + distance:avgHr + distance:max20MinPower + 
##     distance:elevationGain + avgHr:max20MinPower + avgHr:elevationGain + 
##     max20MinPower:elevationGain
## 
##                                Df Sum of Sq   RSS    AIC
## &lt;none&gt;                                      15689 2340.8
## - avgPower:distance             1     43.52 15732 2340.9
## - distance:avgHr                1     64.87 15754 2342.0
## - distance:elevationGain        1    130.08 15819 2345.1
## - avgHr:elevationGain           1    139.64 15828 2345.6
## - avgHr:max20MinPower           1    231.50 15920 2350.0
## - avgBikeCadence:elevationGain  1    611.18 16300 2367.9
## - distance:max20MinPower        1    760.18 16449 2374.8
## - avgPower:avgBikeCadence       1    928.82 16618 2382.6
## - avgBikeCadence:distance       1    959.00 16648 2384.0
## - avgBikeCadence:max20MinPower  1   1293.15 16982 2399.1
## - avgPower:elevationGain        1   1756.77 17446 2419.6
## - max20MinPower:elevationGain   1   2484.52 18173 2450.7</code></pre>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="reg.html#cb258-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(selection)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = avgSpeed ~ avgPower + avgBikeCadence + distance + 
##     avgHr + max20MinPower + elevationGain + avgPower:avgBikeCadence + 
##     avgPower:distance + avgPower:elevationGain + avgBikeCadence:distance + 
##     avgBikeCadence:max20MinPower + avgBikeCadence:elevationGain + 
##     distance:avgHr + distance:max20MinPower + distance:elevationGain + 
##     avgHr:max20MinPower + avgHr:elevationGain + max20MinPower:elevationGain, 
##     data = dat_bike)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -19.7174  -2.3064  -0.2534   2.1279  20.3154 
## 
## Coefficients:
##                                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                   1.999e+02  2.767e+01   7.224 1.26e-12 ***
## avgPower                      1.512e+00  1.975e-01   7.654 6.05e-14 ***
## avgBikeCadence               -2.101e+00  3.041e-01  -6.909 1.05e-11 ***
## distance                     -4.161e-01  1.858e-01  -2.239 0.025442 *  
## avgHr                        -2.298e-01  7.599e-02  -3.024 0.002580 ** 
## max20MinPower                -1.439e+00  1.725e-01  -8.345 3.46e-16 ***
## elevationGain                -7.806e-02  1.384e-02  -5.642 2.39e-08 ***
## avgPower:avgBikeCadence      -1.451e-02  2.190e-03  -6.628 6.55e-11 ***
## avgPower:distance             8.617e-04  6.006e-04   1.435 0.151793    
## avgPower:elevationGain       -3.943e-04  4.325e-05  -9.115  &lt; 2e-16 ***
## avgBikeCadence:distance       1.386e-02  2.058e-03   6.735 3.29e-11 ***
## avgBikeCadence:max20MinPower  1.430e-02  1.828e-03   7.820 1.81e-14 ***
## avgBikeCadence:elevationGain  6.977e-04  1.298e-04   5.376 1.02e-07 ***
## distance:avgHr               -1.151e-03  6.570e-04  -1.752 0.080266 .  
## distance:max20MinPower       -2.595e-03  4.328e-04  -5.996 3.16e-09 ***
## distance:elevationGain        2.587e-05  1.043e-05   2.480 0.013345 *  
## avgHr:max20MinPower           1.010e-03  3.051e-04   3.309 0.000982 ***
## avgHr:elevationGain           1.648e-04  6.412e-05   2.570 0.010367 *  
## max20MinPower:elevationGain   2.872e-04  2.649e-05  10.840  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.598 on 742 degrees of freedom
##   (2074 observations deleted due to missingness)
## Multiple R-squared:  0.8651, Adjusted R-squared:  0.8618 
## F-statistic: 264.4 on 18 and 742 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="exercises-3" class="section level3" number="7.1.7">
<h3><span class="header-section-number">7.1.7</span> Exercises</h3>
<ul>
<li>Design a regression model that will predict best the theoretical average speed for indoor bike activities (that have no speed, no coordinates…).</li>
<li>Feature importance can be very important. Example : to prepare for competitions (that take place between may-september), I always follow a structured training plan at some point. This has a direct impact on the performances. Can you identify when this preparation starts and how to integrate it in the model ? This is somehow connected to your assignment ;)</li>
<li>Can you identify the measurement errors (thanks to residuals)</li>
<li>From the last functional specification used, design a graphic that shows the final impact of an increase in power to the average speed, taking the distance into account.</li>
</ul>
</div>
</div>
<div id="logitic-regression" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Logitic regression</h2>
<div id="mathematical-formulation" class="section level3" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> Mathematical formulation</h3>
<p>Logistic regression aims to model a <em>binary</em> output. In this case, <span class="math inline">\(y \in \{0,1\}\)</span> and the previous specification can’t apply. We still have a linear relationship, but which applies to the log-odd ratio :</p>
<p><span class="math display">\[log \dfrac{\mathbb{P}(y=1|x)}{1-\mathbb{P}(y=1|x)} = log \dfrac{^p}{1-p} = x_ib + \epsilon_i\]</span></p>
<p>This is called the <strong>link function</strong> and working the expression further we find that : <span class="math inline">\(p(x_i;b) = \mathbb{P}(y_i=1|x_i) = \dfrac{1}{1+e^{-x_ib}}\)</span></p>
<p>This allows us to derive the likelihood :</p>
<p><span class="math display">\[\mathcal{L}(b) = \prod_{i=1}^n p(x_i;b)^{y_i} \cdot (1-p(x_i;b))^{1-y_i}\]</span></p>
<p>This expression can be simplified, but there is no exact expression as for the OLS <span class="math inline">\(\rightarrow\)</span> the optimal solution has to be found via numerical optimization (eg Newton-Raphson).</p>
</div>
<div id="implementation-in-r-and-interpretation" class="section level3" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> Implementation in R and interpretation</h3>
<p>In R, we use the <code>glm</code> function while specifying the family. We model the probability of an activity to be bike or something else, which is a binary variable.</p>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="reg.html#cb260-1" aria-hidden="true" tabindex="-1"></a>logit <span class="ot">&lt;-</span> <span class="fu">glm</span>(is_bike<span class="sc">~</span>distance<span class="sc">+</span>duration<span class="sc">+</span>elevationGain<span class="sc">+</span>avgSpeed<span class="sc">+</span>avgHr,<span class="at">data=</span>dat_clean,<span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb260-2"><a href="reg.html#cb260-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(logit)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = is_bike ~ distance + duration + elevationGain + 
##     avgSpeed + avgHr, family = &quot;binomial&quot;, data = dat_clean)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.5243  -0.7947   0.1971   0.5615   3.0610  
## 
## Coefficients:
##                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)    4.592e+00  3.531e-01  13.006  &lt; 2e-16 ***
## distance       2.096e-02  6.167e-03   3.398 0.000679 ***
## duration       3.971e-03  2.308e-03   1.720 0.085343 .  
## elevationGain -7.682e-05  3.781e-05  -2.031 0.042206 *  
## avgSpeed       9.066e-02  8.251e-03  10.988  &lt; 2e-16 ***
## avgHr         -4.760e-02  2.445e-03 -19.468  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 5287.9  on 3819  degrees of freedom
## Residual deviance: 3466.6  on 3814  degrees of freedom
##   (1980 observations deleted due to missingness)
## AIC: 3478.6
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>The sign of the coefficient indicates whether the feature increases the probability for an activity to be a ride ride or not. However, the values cannot be interpreted as directly as in the case of the linear regression. But you can use the exponent of the value of the coefficient and interpret it in terms of odd-ratios.
For instance, adding one more kilometer to the average distance multiplies the probability for an activity to be a ride <em>rather than anything else</em> by 1.0211775, meaning 4% more chances. In the contrary, an activity that has 1 bpm more than the average HR has 4.6483832 6% less chances to be a ride. This makes sense because, as observed earlier, rides are longer and the heart rate is a bit smaller than for other activities.</p>
</div>
<div id="goodness-of-fit" class="section level3" number="7.2.3">
<h3><span class="header-section-number">7.2.3</span> Goodness of fit</h3>
<p>As you might have noticed, there is no <span class="math inline">\(R^2\)</span> or RMSE in our case, just the AIC (which only allows you to compare different models, not know how good the model is). What we can do is check the fitted values of the model and the actual values</p>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="reg.html#cb262-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(logit,dat_clean,<span class="at">type=</span><span class="st">&quot;response&quot;</span>)</span>
<span id="cb262-2"><a href="reg.html#cb262-2" aria-hidden="true" tabindex="-1"></a>pred_bin <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(pred<span class="sc">&gt;</span>.<span class="dv">5</span>)</span>
<span id="cb262-3"><a href="reg.html#cb262-3" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(pred_bin,dat_clean<span class="sc">$</span>is_bike)</span></code></pre></div>
<pre><code>##         
## pred_bin FALSE TRUE
##        0  1688  404
##        1   136 1592</code></pre>
<p>And we can compute the accuracy as the sum of correct predictions divided by total number of activities : 0.8296412
You can derive other goodness of fit metrics from the previous <strong>confusion matrix</strong> :</p>
<ul>
<li>Sensitivity (recall) : <span class="math inline">\(\dfrac{TP}{TP+FN}\)</span></li>
<li>Specificity : <span class="math inline">\(\dfrac{TN}{TN+FP}\)</span></li>
<li>Precision : <span class="math inline">\(\dfrac{TP}{TP+FP}\)</span></li>
</ul>
<p><img src="img/conf_matrix.png" /></p>
<p>Depending on your business use case, you will focus more on one or the other metric. You will cover this in more detail durinng the machine learning week :)</p>
</div>
<div id="exercises-4" class="section level3" number="7.2.4">
<h3><span class="header-section-number">7.2.4</span> Exercises</h3>
<ul>
<li>Fit a model for avgSpeed with all activities (including the activity type)</li>
<li>Fit a model to guess whether an activity is a run or something else</li>
</ul>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multivar.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["DataExploration.pdf", "DataExploration.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
